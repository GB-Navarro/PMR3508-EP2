{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWRYxjUJBYJQ"
   },
   "source": [
    "# **PMR3508 - Exerc√≠cio Programa 02**: <br> **Redes Neurais e o Dataset MNIST**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4S7_SY2jD7xf"
   },
   "source": [
    "## ‚úèÔ∏è **Cabe√ßalho**:\n",
    "\n",
    "### **Nome**: `Gabriel da Silva Navarro`\n",
    "### **NUSP**: `13727908`\n",
    "### **Hash**: `60`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG-GjK2KD_rv"
   },
   "source": [
    "## üìú **Descri√ß√£o:**\n",
    "\n",
    "Neste exerc√≠cio, voc√™ ir√° trabalhar com o **dataset MNIST**, um conjunto de dados com 70.000 imagens de d√≠gitos escritos √† m√£o. Seu objetivo ser√° aplicar os conceitos de **Redes Neurais Artificiais (ANNs)** vistos na aula te√≥rica. Este EP est√° dividido em tarefas, sua formata√ß√£o n√£o deve ser alterada, mas novas c√©lulas de c√≥digo ou texto podem ser criadas nos blocos de cada tarefa.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66eCrGkUEU97"
   },
   "source": [
    "## ‚ö†Ô∏è **Instru√ß√µes:**\n",
    "- Complete todas as tarefas abaixo, respondendo √†s perguntas e escrevendo o c√≥digo necess√°rio.\n",
    "- Comente seu c√≥digo para facilitar a corre√ß√£o.\n",
    "- Entregue o notebook no formato `.ipynb`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvXP1q0XEMTp"
   },
   "source": [
    "## ‚úÖ **Tarefas:**\n",
    "\n",
    "1. **Probabilidades de d√≠gitos no *dataset***       ‚áí `2 pontos`\n",
    "2. **An√°lise Explorat√≥ria de Dados (EDA)**          ‚áí `2 pontos`\n",
    "3. **Treinamento e teste de Modelos**               ‚áí `2 pontos`\n",
    "4. **Comunica√ß√£o de Resultados e Visualiza√ß√µes**    ‚áí `2 pontos`\n",
    "5. **Publica√ß√£o no *Kaggle* e Documenta√ß√£o**        ‚áí `2 pontos`\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "        <h1>\n",
    "        <b>\n",
    "        BOA SORTE !!!\n",
    "        </b>\n",
    "        </h1>\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UNlw6PcAtIW"
   },
   "source": [
    "## ‚è≥ Loading dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up-QY3yPcITN"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "# Configura√ß√£o de seeds para replicabilidade\n",
    "np.random.seed(42)  # Seed para NumPy\n",
    "random.seed(42)     # Seed para o m√≥dulo random\n",
    "\n",
    "input_path = os.getcwd()  # Obt√©m o diret√≥rio atual\n",
    "images_filepath = join(input_path, 'MNIST-images.pkl')\n",
    "labels_filepath = join(input_path, 'MNIST-labels.pkl')\n",
    "validation_images_filepath = join(input_path, 'MNIST-validation-images.pkl')\n",
    "\n",
    "with open(images_filepath, 'rb') as f:\n",
    "    X_tot = pickle.load(f)\n",
    "\n",
    "with open(labels_filepath, 'rb') as f:\n",
    "    y_tot = pickle.load(f)\n",
    "\n",
    "with open(validation_images_filepath, 'rb') as f:\n",
    "    X_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "Oj8ARMguedYL",
    "outputId": "86d3a6f6-94a2-4056-cd53-e95cc800867c"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TESTE DE CARREGAMENTO DO DATASET POR VISUALIZA√á√ÉO\n",
    "Este bloco visualiza algumas imagens do dataset MNIST para verificar se o\n",
    "carregamento foi realizado corretamente.\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    # Fun√ß√£o para mostrar as imagens com seus respectivos t√≠tulos\n",
    "    cols = 3  # N√∫mero de colunas na visualiza√ß√£o\n",
    "    rows = int(len(images) / cols) + 1  # Calcula o n√∫mero de linhas\n",
    "    plt.figure(figsize=(12, 12))  # Define o tamanho da figura\n",
    "    index = 1\n",
    "    for x in zip(images, title_texts):  # Itera sobre as imagens e t√≠tulos\n",
    "        image = x[0]\n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)  # Adiciona um subplot\n",
    "        plt.axis('off')  # Desativa os eixos\n",
    "        plt.imshow(image, cmap=plt.cm.gray)  # Mostra a imagem em escala de cinza\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize=15)  # Define o t√≠tulo da imagem\n",
    "        index += 1\n",
    "    plt.tight_layout()  # Ajusta o layout para evitar sobreposi√ß√£o de t√≠tulos\n",
    "    plt.show()  # Exibe a figura com as imagens e t√≠tulos\n",
    "\n",
    "images_2_show = []  # Lista para armazenar as imagens a serem mostradas\n",
    "titles_2_show = []  # Lista para armazenar os t√≠tulos das imagens\n",
    "# Seleciona aleatoriamente 9 imagens de treino\n",
    "for i in range(0, 9):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(X_tot[r])  # Adiciona a imagem selecionada √† lista\n",
    "    titles_2_show.append(f\"Imagem [{str(r)}] = {str(y_tot[r])}\")  # Adiciona o t√≠tulo correspondente\n",
    "\n",
    "show_images(images_2_show, titles_2_show)  # Exibe as imagens selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59c6DGGoFiiU"
   },
   "source": [
    "# 0Ô∏è‚É£ Suas bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5syjVo2Fh9A"
   },
   "outputs": [],
   "source": [
    "# Importa a biblioteca pandas para lidar com Dataframes.\n",
    "import pandas as pd\n",
    "# Importa o m√≥dulo graph_objects da biblioteca plotly para lidar com visualiza√ß√µes gr√°ficas.\n",
    "import plotly.graph_objects as go\n",
    "# Importa o m√≥dulo pyplot da biblioteca matplotlib para lidar com a visualiza√ß√£o de imagens.\n",
    "import matplotlib.pyplot as plt\n",
    "# Importa o objeto Optional da biblioteca typing para lidar com tipagens opcionais.\n",
    "from typing import Optional\n",
    "# Importa do m√≥dulo model_selection da biblioteca sklearn o m√©todo train_test_split para separar os dados em treino e teste.\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importa do m√≥dulo preprocessing da biblioteca sklearn o objeto MinMaxScaler para normalizar os dados.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Importa do m√≥dulo neural_network da biblioteca sklearn o objeto MLPClassifier para criar a rede neural.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Importa do m√≥dulo model_selection da biblioteca sklearn o objeto GridSearchCV.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Importa do m√≥dulo metrics da biblioteca sklearn os m√©todos classification_report, accuracy_score e confusion_matrix \n",
    "# para gerar as m√©tricas de avalia√ß√£o.\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqDjIWMMKrwp"
   },
   "source": [
    "# 1Ô∏è‚É£ Tarefa 01: Probabilidades üé≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGh3ahlqLwZO"
   },
   "source": [
    "## üßëüèª‚Äçüíª Item a)\n",
    "\n",
    "Descubra o n√∫mero do Dataset associado ao seu Hash.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vari√°vel \"y_tot\" cont√©m os r√≥tulos (labels) das imagens no Dataset. \n",
    "# Sabendo que meu hash √© 60, o c√≥digo abaixo identifica o r√≥tulo do Dataset correspondente ao meu hash.\n",
    "print(f\"O n√∫mero do Dataset associado ao meu hash √©: {y_tot[60]}.\")\n",
    "\n",
    "# Caso eu deseje visualizar a imagem associada ao meu hash no Dataset,\n",
    "# o c√≥digo abaixo exibe a imagem correspondente com o r√≥tulo indicado no t√≠tulo.\n",
    "plt.imshow(X_tot[60], cmap='gray')  # Exibe a imagem em escala de cinza.\n",
    "plt.title(f\"D√≠gito: {y_tot[60]}\")   # Mostra o r√≥tulo da imagem como t√≠tulo.\n",
    "plt.axis('off')                     # Remove os eixos para uma exibi√ß√£o mais limpa.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhFiXcpKRVMA"
   },
   "source": [
    "## üî¶ Item b)\n",
    "\n",
    "Determine, para a imagem vinculada ao seu Hash, qual √© a Probabilidade de um p√≠xel claro (128 - 225) para esta √∫nica imagem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WO_UkOyCRtvs"
   },
   "outputs": [],
   "source": [
    "# Inicializa a vari√°vel para contar o n√∫mero de pixels claros.\n",
    "bright_pixels_number = 0\n",
    "\n",
    "# Calcula o total de pixels na imagem (28x28 √© a dimens√£o padr√£o das imagens do Dataset).\n",
    "total_pixels_number = 28 * 28\n",
    "\n",
    "# Itera por cada linha de pixels na imagem associada ao hash (X_tot[60]).\n",
    "for line in X_tot[60]:\n",
    "    # Conta os pixels claros (valores >= 128) na linha e adiciona ao total.\n",
    "    bright_pixels_number += len(line[line >= 128])\n",
    "    \n",
    "# Calcula e exibe a probabilidade de um pixel ser claro, formatando o resultado como porcentagem.\n",
    "print(f\"Para a imagem vinculada ao meu Hash, a probabilidade de um pixel claro (128 - 255) \\\n",
    "ocorrer √© de aproximadamente {((bright_pixels_number / total_pixels_number) * 100):.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7I1XtkhRuTH"
   },
   "source": [
    "## ‚ôüÔ∏è Item c)\n",
    "\n",
    "Qual √© a probabilidade de um p√≠xel ser claro dentre todos os p√≠xeis que tem a mesma classe que a sua imagem obtida em a)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wvg4-TnHStBN"
   },
   "outputs": [],
   "source": [
    "# Obt√©m os √≠ndices de todas as imagens no Dataset que pertencem √† classe 1 (ou seja, possuem r√≥tulo igual a 1).\n",
    "same_class_indexes = np.where(y_tot == 1)[0]\n",
    "\n",
    "# Inicializa a vari√°vel para contar o n√∫mero total de pixels claros.\n",
    "bright_pixels_number = 0\n",
    "\n",
    "# Calcula o total de pixels considerando todas as imagens da mesma classe (28x28 pixels por imagem multiplicado pela\n",
    "# quantidade de imagens na classe).\n",
    "total_pixels_number = 28 * 28 * len(same_class_indexes)\n",
    "\n",
    "# Itera por cada √≠ndice das imagens pertencentes √† classe 1.\n",
    "for index in same_class_indexes:\n",
    "    # Recupera a matriz de pixels da imagem correspondente ao √≠ndice atual.\n",
    "    element = X_tot[index]\n",
    "    # Conta os pixels claros (valores >= 128) na imagem atual e soma ao total acumulado.\n",
    "    bright_pixels_number += len(element[element >= 128])\n",
    "\n",
    "# Calcula e exibe a probabilidade de um pixel claro (128 - 255) ocorrer, formatando o resultado como porcentagem.\n",
    "print(f\"Para as imagens vinculadas √† classe 1, a probabilidade de um pixel claro (128 - 255) \\\n",
    "ocorrer √© de aproximadamente {((bright_pixels_number / total_pixels_number) * 100):.2f}%.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dudVaTPOSrzd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a8k73BRHMJE"
   },
   "source": [
    "# 2Ô∏è‚É£ Tarefa 02: An√°lise Explorat√≥ria de Dados üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxW_LjGSJBk4"
   },
   "source": [
    "## ‚ú® Item a)\n",
    "\n",
    "Conte quantas vezes cada d√≠gito (de 0 a 9) aparece e responda:\n",
    "\n",
    "1. Todos os d√≠gitos aparecem a mesma quantidade?\n",
    "\n",
    "2. Qual o valor m√©dio dos p√≠xeis de cada d√≠gito?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnjQQAATJUVr"
   },
   "outputs": [],
   "source": [
    "# Obt√©m todos os valores √∫nicos de d√≠gitos (r√≥tulos) presentes no Dataset.\n",
    "unique_digits = np.unique(y_tot)\n",
    "\n",
    "# Itera por cada d√≠gito √∫nico encontrado no Dataset.\n",
    "for digit in unique_digits:\n",
    "    # Obt√©m os √≠ndices das imagens que pertencem ao d√≠gito atual.\n",
    "    digit_indexes = np.where(y_tot == digit)[0]\n",
    "    \n",
    "    # Inicializa a vari√°vel para acumular a soma dos valores dos pixels para o d√≠gito atual.\n",
    "    pixels_sum = 0\n",
    "    \n",
    "    # Itera por cada √≠ndice associado ao d√≠gito atual.\n",
    "    for index in digit_indexes:\n",
    "        # Soma os valores de todos os pixels da imagem atual ao total acumulado.\n",
    "        pixels_sum += np.sum(X_tot[index])\n",
    "    \n",
    "    # Exibe informa√ß√µes sobre o d√≠gito atual.\n",
    "    print(f\"Informa√ß√µes sobre o d√≠gito '{digit}':\")\n",
    "    \n",
    "    # Calcula o n√∫mero de imagens no Dataset classificadas como o d√≠gito atual.\n",
    "    digits_number = len(y_tot[y_tot == digit])\n",
    "    \n",
    "    # Exibe a quantidade de d√≠gitos do tipo atual no Dataset.\n",
    "    print(f\"        Existem {digits_number} d√≠gitos '{digit}' no Dataset.\")\n",
    "    \n",
    "    # Calcula e exibe o valor m√©dio dos pixels das imagens do d√≠gito atual.\n",
    "    print(f\"        O valor m√©dio dos p√≠xeis dos d√≠gitos classificados como '{digit}' √© aproximadamente {(pixels_sum) / (digits_number * 28 * 28):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpfIZzxlMDsX"
   },
   "source": [
    "##### ***Resposta 01:***\n",
    "\n",
    "***O Dataset em quest√£o possui:***\n",
    "\n",
    "- ***5920 iguais d√≠gitos √† '0'.***\n",
    "\n",
    "\n",
    "- ***6725 iguais d√≠gitos √† '1'.***\n",
    "\n",
    "\n",
    "- ***6023 iguais d√≠gitos √† '2'.***\n",
    "\n",
    "\n",
    "- ***6107 iguais d√≠gitos √† '3'.***\n",
    "\n",
    "\n",
    "- ***5918 iguais d√≠gitos √† '4'.***\n",
    "\n",
    "\n",
    "- ***5376 iguais d√≠gitos √† '5'.***\n",
    "  \n",
    "\n",
    "- ***5915 iguais d√≠gitos √† '6'.***\n",
    "\n",
    "\n",
    "- ***6238 iguais d√≠gitos √† '7'.***\n",
    "\n",
    "\n",
    "- ***5856 iguais d√≠gitos √† '8'.***\n",
    "\n",
    "\n",
    "- ***5922 iguais d√≠gitos √† '9'.***\n",
    "\n",
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tUHVN9uMGdy"
   },
   "source": [
    "##### ***Resposta 02:***\n",
    "\n",
    "***N√£o, os d√≠gitos aparecem em diferentes quantidades.***\n",
    "\n",
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Prl_N5YMMIXr"
   },
   "source": [
    "##### ***Resposta 03:*** \n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '0' √©, aproximadamente: 44.23.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '1' √©, aproximadamente: 19.40.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '2' √©, aproximadamente: 38.02.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '3' √©, aproximadamente: 36.23.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '4' √©, aproximadamente: 31.04.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '5' √©, aproximadamente: 32.92.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '6' √©, aproximadamente: 35.24.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '7' √©, aproximadamente: 29.26.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '8' √©, aproximadamente: 38.40.***\n",
    "\n",
    "\n",
    "- ***O valor m√©dio dos p√≠xeis cujos d√≠gitos s√£o classificados como '9' √©, aproximadamente: 31.34.***\n",
    "\n",
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX5d6s4EJTf8"
   },
   "source": [
    "## üìè Item b)\n",
    "\n",
    "Fa√ßa um histograma que mostre a distribui√ß√£o dos valores dos p√≠xeis para cada d√≠gito. H√° muitos valores que s√£o ‚Äúapagados‚Äù (ou seja, com valor 0) ou a distribui√ß√£o dos valores √© mais equilibrada entre os d√≠gitos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista onde cada posi√ß√£o `i` cont√©m um array unidimensional com todos os valores de pixels das imagens classificadas como o d√≠gito `i`.\n",
    "# Por exemplo, o √≠ndice 0 armazena um array com os valores de pixels de todas as imagens classificadas como 0. \n",
    "results = [X_tot[y_tot == digit].reshape(-1) for digit in np.unique(y_tot)]\n",
    "\n",
    "\n",
    "# Nota mental: O numpy √© eficiente para opera√ß√µes vetorizadas. Portanto, √© sempre melhor usar tais opera√ß√µes ao inv√™s de la√ßos expl√≠citos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(data: pd.Series, title: Optional[str] = \"\", xaxis_title: Optional[str] = \"\", yaxis_title: Optional[str] = \"\") -> None:\n",
    "    '''\n",
    "        Descri√ß√£o:\n",
    "            Essa fun√ß√£o plota um histograma a partir do conjunto de dados (pd.Series) recebido como par√¢metro.\n",
    "        Argumentos:\n",
    "            data (pd.Series): O conjunto de dados a ser visualizado como histograma.\n",
    "            title (str): T√≠tulo do histograma. Por padr√£o, √© uma string vazia.\n",
    "            xaxis_title (str): R√≥tulo para o eixo x. Por padr√£o, √© uma string vazia.\n",
    "            yaxis_title (str): R√≥tulo para o eixo y. Por padr√£o, √© uma string vazia.\n",
    "        Retorno:\n",
    "            None: A fun√ß√£o gera e exibe o histograma, mas n√£o retorna nenhum valor.\n",
    "    '''\n",
    "    \n",
    "    # Cria um objeto `Figure` para construir o histograma.\n",
    "    fig = go.Figure(\n",
    "        # Adiciona os dados ao histograma.\n",
    "        data=[go.Histogram(\n",
    "            x=data,     # O eixo x recebe os valores do conjunto de dados (pd.Series) recebido como par√¢metro.\n",
    "            nbinsx=20   # O n√∫mero de intervalos (bins) √© configurado como 20.\n",
    "        )]\n",
    "    )\n",
    "\n",
    "    # Atualiza o layout do plot.\n",
    "    fig.update_layout(\n",
    "        # Define o t√≠tulo do plot.\n",
    "        title=title,\n",
    "        # Define o r√≥tulo para o eixo x.\n",
    "        xaxis_title=xaxis_title,\n",
    "        # Define o r√≥tulo para o eixo y.\n",
    "        yaxis_title=yaxis_title,\n",
    "        # Ajusta o espa√ßo entre as barras no histograma.\n",
    "        bargap=0.1\n",
    "    )\n",
    "\n",
    "    # Exibe o histograma.\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cada d√≠gito √∫nico na lista `unique_digits`, gera e exibe um histograma que mostra a distribui√ß√£o \n",
    "# dos valores dos pixels associados a esse d√≠gito.\n",
    "for digit in unique_digits:\n",
    "    plot_histogram(results[digit], f\"Distribui√ß√£o dos valores dos p√≠xeis do d√≠gito {digit}\", \"Valores\", \"Quantidade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgl92AXbJR9B"
   },
   "source": [
    "## ü§ì Item c)\n",
    "\n",
    "Crie uma imagem para cada d√≠gito (de 0 a 9) em que cada p√≠xel dessa nova imagem representa a m√©dia do valor dos p√≠xeis para aquela classe. Voc√™ consegue reconhecer os d√≠gitos nas imagens criadas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hv4CKY55JVkx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuy1gZFcJVnc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1w4-cPCJVqT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ-YKsEWJOhZ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLzAAnAGHQYx"
   },
   "source": [
    "# 3Ô∏è‚É£ Tarefa 03: Treinamento e Teste de Modelos ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGx_wlftUhq_"
   },
   "source": [
    "## üìà Item a)\n",
    "\n",
    "Treine a ANN1 com 784 entradas, 8 neur√¥nios na 1‚Å†¬™ camada oculta, 8 neur√¥nios na 2‚Å†¬™ camada oculta e 10 sa√≠das. Utilize 5 √©pocas para o treinamento. Use a biblioteca `scikit-learn`:\n",
    "\n",
    "- Input Layer: 784 entradas (28x28);\n",
    "- Hidden Layer 1: 8 neur√¥nios;\n",
    "- Hidden Layer 2: 8 neur√¥nios;\n",
    "- Output Layer: 10 sa√≠das; (Classificador 0-9)\n",
    "- Treine com 10 √©pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria c√≥pias dos arrays X_tot e y_tot e os atribui a X e y, respectivamente, para garantir que as vari√°veis originais n√£o sejam modificadas\n",
    "# durante o processamento.\n",
    "X, y = np.copy(X_tot), np.copy(y_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj6cAvy-ZPiy"
   },
   "outputs": [],
   "source": [
    "# Divide os dados em conjuntos de treinamento (80%) e teste (20%) de forma aleat√≥ria.\n",
    "# X e y s√£o as features e r√≥tulos, respectivamente. A semente random_state=10 garante reprodutibilidade dos resultados.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensiona o conjunto de dados de treinamento (X_train) para transform√°-lo em um array 2D. Originalmente, cada imagem no MNIST \n",
    "# tem forma 28x28 (uma matriz 2D).  O m√©todo reshape altera essa forma para um vetor unidimensional (1D) com 28*28 = 784 elementos. O par√¢metro \n",
    "# `-1` calcula automaticamente o n√∫mero de colunas necess√°rias, preservando o n√∫mero de amostras (linhas).\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Redimensiona o conjunto de dados de teste (X_test) da mesma maneira que o conjunto de treinamento.\n",
    "# Isso garante que os dados de entrada estejam no mesmo formato (vetores 1D com 784 elementos por exemplo).\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Observa√ß√£o:\n",
    "# Esse redimensionamento √© necess√°rio porque muitos modelos de machine learning, como redes neurais ou classificadores do scikit-learn,\n",
    "# esperam dados em forma de vetores 1D, em vez de matrizes 2D ou imagens estruturadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-lDDeAfZPlK"
   },
   "outputs": [],
   "source": [
    "# Cria o objeto MinMaxScaler, que normaliza os dados para a faixa [0, 1].\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplica a normaliza√ß√£o nos dados de treinamento, ajustando o scaler aos dados e transformando-os.\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplica a normaliza√ß√£o nos dados de teste, utilizando os par√¢metros calculados a partir dos dados de treinamento.\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o primeiro modelo de rede neural, usando o MLPClassifier (MultiLayer Perceptron Classifier) do scikit-learn para tal.\n",
    "mlp_1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(8, 8),  # Define duas camadas ocultas (hidden layers), cada uma com 8 neur√¥nios.\n",
    "    activation='relu',          # Define a fun√ß√£o de ativa√ß√£o como ReLU (Rectified Linear Unit).\n",
    "    solver='adam',              # Utiliza o otimizador Adam para ajustar os pesos durante o treinamento.\n",
    "    max_iter=10,                # Define o n√∫mero m√°ximo de itera√ß√µes do otimizador (similar ao n√∫mero de √©pocas em outros frameworks).\n",
    "    validation_fraction=0.1,    # Reserva 10% dos dados de treinamento para valida√ß√£o durante o treinamento.\n",
    "    early_stopping=True,        # Interrompe o treinamento se a pontua√ß√£o no conjunto de valida√ß√£o n√£o melhorar por um n√∫mero consecutivo de itera√ß√µes (paci√™ncia padr√£o = 10).\n",
    "    random_state=10             # Define a semente para reprodutibilidade dos resultados, garantindo que os pesos iniciais e a divis√£o de valida√ß√£o sejam consistentes entre execu√ß√µes.\n",
    ")\n",
    "\n",
    "# Treina o modelo com os dados de treino.\n",
    "mlp_1.fit(X_train, y_train) \n",
    "\n",
    "# Observa√ß√µes: \n",
    "# 1. A input layer j√° √© automaticamente configurada dentro do MLPClassifier como sendo o n√∫mero total \n",
    "#    de features (atributos) no conjunto de dados de entrada. Ou seja, o n√∫mero de neur√¥nios na camada de entrada\n",
    "#    ser√° igual ao n√∫mero de colunas (features) em X_train, que √© 784 (28 x 28).\n",
    "# 2. A fun√ß√£o de sa√≠da padr√£o do MLPClassifier para problemas de classifica√ß√£o multiclasse √© a \n",
    "#    fun√ß√£o softmax. Ela gera uma probabilidade para cada classe, e a classe com a maior probabilidade \n",
    "#    √© escolhida como a previs√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza as previs√µes usando a ANN1.\n",
    "y_pred_1 = mlp_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVaSP7OGXD2d"
   },
   "source": [
    "## üìâ Item b)\n",
    "\n",
    "Treine a ANN2 com 784 entradas, 256 neur√¥nios na 1‚Å†¬™ camada oculta, 256 neur√¥nios na 2‚Å†¬™ camada oculta, 256 neur√¥nios na 3¬™ camada oculta, 256 neur√¥nios na 4¬™ camada oculta e 10 sa√≠das. Utilize 20 √©pocas dessa vez. Use a biblioteca `scikit-learn`.\n",
    "\n",
    "- Input Layer: 784 entradas (28x28);\n",
    "- Hidden Layer 1: 256 neur√¥nios;\n",
    "- Hidden Layer 2: 256 neur√¥nios;\n",
    "- Hidden Layer 3: 256 neur√¥nios;\n",
    "- Hidden Layer 4: 256 neur√¥nios;\n",
    "- Output Layer: 10 sa√≠das; (Classifica√ß√£o 0-9)\n",
    "- Treine com 20 √©pocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a varia√ß√£o percentual na curva de perda entre a √©poca 5 e a √∫ltima √©poca\n",
    "loss_curve_1_pct_change = ((mlp_1_loss_curve_values[5] - mlp_1_loss_curve_values[len(mlp_1_loss_curve_values) - 1]) / mlp_1_loss_curve_values[5]) * 100\n",
    "\n",
    "# Calcula a varia√ß√£o percentual na pontua√ß√£o de valida√ß√£o (acur√°cia) entre a √©poca 5 e a √∫ltima √©poca\n",
    "validation_scores_1_pct_change = ((mlp_1_validation_scores[5] - mlp_1_validation_scores[len(mlp_1_validation_scores) - 1]) / mlp_1_validation_scores[5]) * 100\n",
    "\n",
    "# Exibe a queda percentual na curva de perda entre a √©poca 5 e a √∫ltima √©poca\n",
    "print(f\"Entre a √©poca 5 e a √©poca {len(mlp_1_loss_curve_values)-1} houve uma queda de {loss_curve_1_pct_change:.2f}% na curva de perda.\\n\")\n",
    "\n",
    "# Exibe o aumento percentual na acur√°cia entre a √©poca 5 e a √∫ltima √©poca (o sinal negativo √© invertido para apresentar um aumento positivo)\n",
    "print(f\"Entre a √©poca 5 e a √©poca {len(mlp_1_validation_scores)-1} houve um aumento de {-validation_scores_1_pct_change:.2f}% na acur√°cia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8HddFrTZP8P"
   },
   "outputs": [],
   "source": [
    "# Cria o segundo modelo de rede neural, usando o MLPClassifier (MultiLayer Perceptron Classifier) do scikit-learn para tal.\n",
    "mlp_2 = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 256, 256, 256),  # Define quatro camadas ocultas (hidden layers), cada uma com 256 neur√¥nios.\n",
    "    activation='relu',                        # Define a fun√ß√£o de ativa√ß√£o como ReLU (Rectified Linear Unit).\n",
    "    solver='adam',                            # Utiliza o otimizador Adam para ajustar os pesos durante o treinamento.\n",
    "    max_iter=20,                              # Define o n√∫mero m√°ximo de itera√ß√µes do otimizador (similar ao n√∫mero de √©pocas em outros frameworks).\n",
    "    validation_fraction=0.1,                  # Reserva 10% dos dados de treinamento para valida√ß√£o durante o treinamento.\n",
    "    early_stopping=True,                      # Interrompe o treinamento se a pontua√ß√£o no conjunto de valida√ß√£o n√£o melhorar por um n√∫mero consecutivo de itera√ß√µes (paci√™ncia padr√£o = 10).\n",
    "    random_state=10                           # Define a semente para reprodutibilidade dos resultados, garantindo que os pesos iniciais e a divis√£o de valida√ß√£o sejam consistentes entre execu√ß√µes.\n",
    ")\n",
    "\n",
    "# Treina o modelo com os dados de treino.\n",
    "mlp_2.fit(X_train, y_train) \n",
    "\n",
    "# Observa√ß√µes: \n",
    "# 1. A input layer j√° √© automaticamente configurada dentro do MLPClassifier como sendo o n√∫mero total \n",
    "#    de features (atributos) no conjunto de dados de entrada. Ou seja, o n√∫mero de neur√¥nios na camada de entrada\n",
    "#    ser√° igual ao n√∫mero de colunas (features) em X_train, que √© 784 (28 x 28).\n",
    "# 2. A fun√ß√£o de sa√≠da padr√£o do MLPClassifier para problemas de classifica√ß√£o multiclasse √© a \n",
    "#    fun√ß√£o softmax. Ela gera uma probabilidade para cada classe, e a classe com a maior probabilidade \n",
    "#    √© escolhida como a previs√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k21D57OzZP_K"
   },
   "outputs": [],
   "source": [
    "# Realiza as previs√µes usando a ANN2.\n",
    "y_pred_2 = mlp_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me4UkIkmXCkJ"
   },
   "source": [
    "## ‚öôÔ∏è Item c)\n",
    "\n",
    "Agora voc√™ treinar√° um novo modelo, mais adequado. Para isso, gere ao menos 5 configura√ß√µes de redes neurais, variando o n√∫mero de camadas ocultas, o n√∫mero de neur√¥nios e o n√∫mero de √©pocas. As configura√ß√µes devem estar intermedi√°rias entre `[8, 8]` e `[256, 256, 256, 256]`.\n",
    "\n",
    "Utilize a fun√ß√£o `GridSearchCV` para realizar uma busca exaustiva pelos hiperpar√¢metros e encontre a configura√ß√£o que oferece o melhor classificador, justificando sua escolha com base nas m√©tricas de valida√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tsEhq4XZQaG"
   },
   "outputs": [],
   "source": [
    "# Define o modelo base (MLPClassifier - MultiLayer Perceptron Classifier) a ser usado no GridSearchCV.\n",
    "mlp = MLPClassifier(random_state=10, early_stopping=True)\n",
    "\n",
    "# Define os par√¢metros para a busca em grade.\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(8, 8), (64, 64, 64), (128,128,128), (256, 256, 256, 256)],  # Define os conjuntos de camadas que ser√£o testados.\n",
    "    'activation': ['relu'],                                                             # Define as fun√ß√µes de ativa√ß√£o que ser√£o testadas. \n",
    "    'solver': ['adam'],                                                                 # Define os otimizadores que ser√£o testados.\n",
    "    'max_iter': [10, 50, 100, 200],                                                     # Define os n√∫meros de itera√ß√µes (√©pocas) que ser√£o testados.\n",
    "}\n",
    "\n",
    "# Cria uma inst√¢ncia do GridSearchCV usando as vari√°veis definidas acima.\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Treina o modelo usando GridSearchCV, visando encontrar a melhor combina√ß√£o dentre as \n",
    "# poss√≠veis configura√ß√µes de hiperpar√¢metros definidas na vari√°vel `param_grid`.\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l03osQlrZQc3"
   },
   "outputs": [],
   "source": [
    "# Exibe os melhores hiperpar√¢metros encontrados.\n",
    "print(\"Melhores hiperpar√¢metros encontrados: \", grid_search.best_params_)\n",
    "\n",
    "print()\n",
    "\n",
    "# Exibe a acur√°cia do modelo com os melhores hiperpar√¢metros.\n",
    "print(\"Acur√°cia do modelo com os melhores hiperpar√¢metros (no conjunto de teste): \", grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note que o modelo com os hiperpar√¢metros otimizados pelo GridSearchCV apresenta uma acur√°cia ligeiramente superior √† do segundo modelo (ANN2). Considerando que ambos possuem a mesma configura√ß√£o de camadas e diferem apenas no n√∫mero de √©pocas, faz sentido classificar o modelo ajustado pelo GridSearchCV como o melhor entre os dois, devido ao seu desempenho ligeiramente superior.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-28FKAyEZQe5"
   },
   "outputs": [],
   "source": [
    "# Cria o modelo de rede neural utilizando o MLPClassifier (Multi-Layer Perceptron Classifier) do scikit-learn, \n",
    "# configurado com os melhores hiperpar√¢metros  obtidos atrav√©s da busca exaustiva realizada pelo GridSearchCV.\n",
    "best_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 256, 256, 256),  # Define quatro camadas ocultas (hidden layers), cada uma com 256 neur√¥nios.\n",
    "    activation='relu',                        # Define a fun√ß√£o de ativa√ß√£o como ReLU (Rectified Linear Unit).\n",
    "    solver='adam',                            # Utiliza o otimizador Adam para ajustar os pesos durante o treinamento.\n",
    "    max_iter=50,                              # Define o n√∫mero m√°ximo de itera√ß√µes do otimizador (similar ao n√∫mero de √©pocas em outros frameworks).\n",
    "    validation_fraction=0.1,                  # Reserva 10% dos dados de treinamento para valida√ß√£o durante o treinamento.\n",
    "    early_stopping=True,                      # Interrompe o treinamento se a pontua√ß√£o no conjunto de valida√ß√£o n√£o melhorar por um n√∫mero consecutivo de itera√ß√µes (paci√™ncia padr√£o = 10).\n",
    "    random_state=10                           # Define a semente para reprodutibilidade dos resultados, garantindo que os pesos iniciais e a divis√£o de valida√ß√£o sejam consistentes entre execu√ß√µes.\n",
    ")\n",
    "\n",
    "# Treina o modelo com os dados de treino.\n",
    "best_mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza as previs√µes usando a melhor ANN encontrada.\n",
    "best_y_pred = best_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkOTVK9WXBHT"
   },
   "source": [
    "## üîß Item d)\n",
    "\n",
    "Para os modelos treinados nas quest√µes a) e b), al√©m do classificador encontrado na quest√£o c), compare o desempenho dos modelos, analisando se apresentam *underfitting* ou *overfitting*. Justifique com gr√°ficos e an√°lises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Comparando o desempenho dos modelos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula e exibe a acur√°cia do modelo ANN1 utilizando as predi√ß√µes y_pred_1.\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
    "print(f\"Acur√°cia da ANN1: {accuracy_1}\\n\")\n",
    "\n",
    "# Calcula e exibe a acur√°cia do modelo ANN2 utilizando as predi√ß√µes y_pred_2.\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
    "print(f\"Acur√°cia da ANN2: {accuracy_2}\\n\")\n",
    "\n",
    "# Calcula e exibe a acur√°cia do melhor modelo de rede neural encontrado.\n",
    "best_accuracy = accuracy_score(y_test, best_y_pred)\n",
    "print(f\"Acur√°cia da melhor ANN encontrada: {best_accuracy}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Com base nas acur√°cias obtidas, podemos comparar o desempenho dos modelos da seguinte maneira:*\n",
    "\n",
    "*- **ANN1 (~ 0.9098 accuracy):** Obteve uma acur√°cia de aproximadamente 91%, o que indica um desempenho bom, por√©m inferior aos outros modelos testados.*\n",
    "\n",
    "*- **ANN2 (~ 0.9784 accuracy):** Apresentou uma melhoria significativa, com acur√°cia de 97,8%. Essa melhoria sugere que o aumento no n√∫mero de camadas, neur√¥nios por camada e √©pocas contribuiu para uma maior efici√™ncia na tarefa de classifica√ß√£o.*\n",
    "\n",
    "*- **Melhor ANN Encontrada (~ 0.9822 accuracy):** Com uma acur√°cia de 98,2%, este modelo superou os outros, indicando que o ajuste fino dos hiperpar√¢metros via GridSearchCV (como o aumento de 20 para 50 √©pocas) otimizou ainda mais seu desempenho, tornando-o o mais preciso dos tr√™s.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printa um relat√≥rio detalhado dos resultados da classifica√ß√£o feita pela ANN1.\n",
    "print(classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printa um relat√≥rio detalhado dos resultados da classifica√ß√£o feita pela ANN2.\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printa um relat√≥rio detalhado dos resultados da classifica√ß√£o feita pela melhor ANN encontrada.\n",
    "print(classification_report(y_test, best_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANN1 - MLP com 2 Camadas Ocultas (8 neur√¥nios por camada + 10 epochs):***\n",
    "\n",
    "*O primeiro modelo, utilizando um MLPClassifier com duas camadas ocultas de 8 neur√¥nios cada, apresentou um desempenho geral bom, com uma acur√°cia de 91%. As classes 0 e 1 obtiveram os melhores resultados, com precis√£o e recall superiores a 0,95. Por outro lado, as classes 5 e 8 tiveram o pior desempenho, com ambos os indicadores em torno de 0,87. As demais classes apresentaram resultados um pouco mais consistentes, com valores de precis√£o e recall variando entre 0,88 e 0,93.*\n",
    "\n",
    "***ANN2 - MLP com 4 Camadas Ocultas (256 neur√¥nios por camada + 20 epochs):***\n",
    "\n",
    "*O segundo modelo, utilizando um MLPClassifier com quatro camadas ocultas de 256 neur√¥nios cada, apresentou um desempenho significativamente superior ao primeiro. A acur√°cia aumentou para 98%, enquanto o recall e o F1-score tamb√©m atingiram 0,98. A maioria das classes registrou valores de precis√£o e recall pr√≥ximos a 0,98, com exce√ß√£o das classes 8 e 9, que, embora ainda ligeiramente inferiores, exibiram melhorias substanciais em rela√ß√£o ao primeiro modelo.*\n",
    "\n",
    "***Melhor ANN encontrada - MLP com 4 Camadas Ocultas (256 neur√¥nios por camada + 50 epochs):***\n",
    "\n",
    "*O terceiro modelo √© uma vers√£o do MLPClassifier com a mesma arquitetura do segundo modelo (quatro camadas ocultas de 256 neur√¥nios), mas treinado com um n√∫mero maior de √©pocas. Esse modelo alcan√ßou uma acur√°cia de 98%, apresentando desempenho quase id√™ntico ao segundo, por√©m com pequenas melhorias nos √≠ndices de precis√£o e recall para as classes 8 e 9.*\n",
    "\n",
    "*Em resumo, o terceiro modelo, com uma arquitetura maior e mais √©pocas de treinamento, apresentou um salto significativo em desempenho em rela√ß√£o ao primeiro modelo e uma leve vantagem sobre o segundo, consolidando-se como o melhor entre os tr√™s. O segundo modelo, por sua vez, tamb√©m mostrou uma grande melhora em compara√ß√£o ao primeiro, que, apesar de ser o menos eficiente, ainda alcan√ßou mais de 90% de acur√°cia e pode ser considerado satisfat√≥rio.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Analisando se os modelos apresentam underfitting ou overfitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2GOevKqZQ4g"
   },
   "outputs": [],
   "source": [
    "def plot_multiples_time_series_line_graphs(data_list: list, serie_title: Optional[str] = \"\", serie_xaxis_title: Optional[str] = \"\", \n",
    "                               serie_yaxis_title: Optional[str] = \"\", annotation_text: Optional[str] = \"\") -> None:\n",
    "    '''\n",
    "        Description:\n",
    "            Esta fun√ß√£o exibe em um mesmo plot m√∫ltiplos gr√°ficos de s√©ries temporais. \n",
    "        Args:\n",
    "            data_list (list): Lista contendo as s√©ries temporais cujos gr√°ficos ser√£o exibidos no plot. Os valores de tais s√©ries temporais\n",
    "                              estar√£o no eixo y, enquanto os √≠ndices dessas s√©ries estar√£o no eixo x.\n",
    "            title (string) [Optional]: T√≠tulo do plot.\n",
    "            xaxis_title (string) [Optional]: T√≠tulo do eixo x do plot.\n",
    "            yaxis_title (string) [Optional]: T√≠tulo do eixo y do plot.\n",
    "        Return:\n",
    "            None: A fun√ß√£o exibe os gr√°ficos, mas n√£o retorna nenhum valor.  \n",
    "        Errors:\n",
    "            TypeError: √â esperado que todas os elementos da lista \"data_list\" sejam objetos do tipo pd.Series, isto √©, que sejam s√©ries temporais.\n",
    "            ValueError: √â esperado que todas as s√©ries temporais presentes na vari√°vel \"data_list\" possuam os mesmos √≠ndices. \n",
    "            TypeError: √â esperado que todas as s√©ries temporais presentes na vari√°vel data_list possuam um atributo \"name\".\n",
    "    '''    \n",
    "\n",
    "    # Verifica se todos os elementos presentes na lista \"data_list\" s√£o s√©ries temporais.\n",
    "    are_all_data_time_series = all(isinstance(df, pd.Series) for df in data_list)\n",
    "    \n",
    "    # Retorna um erro caso algum dos dados presentes na vari√°vel \"data_list\" n√£o seja uma s√©rie temporal\n",
    "    if not are_all_data_time_series:\n",
    "        raise TypeError(\"Todos os dados presentes no par√¢metro 'data_list' devem ser s√©ries temporais.\")\n",
    "    \n",
    "    # Verifica se as s√©ries temporais presentes na vari√°vel \"data_list\" possuem os mesmos √≠ndices.\n",
    "    are_all_index_equal = all(df.index.equals(data_list[0].index) for df in data_list)\n",
    "    \n",
    "    # Retorna um erro caso as s√©ries temporais possuam √≠ndices diferentes.\n",
    "    if not are_all_index_equal:\n",
    "        raise ValueError(\"Todos as s√©ries temporais devem possuir os mesmos √≠ndices.\")\n",
    "    \n",
    "    # Verifica se todas as s√©ries temporais presentes na vari√°vel \"data_list\" possuem o atributo \"name\".\n",
    "    all_time_series_have_names = all(hasattr(df,\"name\") for df in data_list)\n",
    "    \n",
    "    # Retorna um erro caso uma das s√©ries temporais presentes na vari√°vel \"data_list\" n√£o possua o atributo \"name\".\n",
    "    if not all_time_series_have_names:\n",
    "        raise TypeError(\"Todas as s√©ries temporais devem possuir o atributo 'name'\")\n",
    "    \n",
    "    # Cria uma lista de timestamps que representar√° o eixo x do gr√°fico que ser√° plotado.\n",
    "    x_axis = data_list[0].index.tolist() # Observe que s√≥ podemos fazer isso pois temos certeza que todas as s√©ries temporais possuem os mesmos √≠ndices.\n",
    "    # Cria a figura onde ser√° plotado o gr√°fico.\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adiciona cada s√©rie temporal ao gr√°fico.\n",
    "    for time_serie in data_list:\n",
    "        # Plota o gr√°fico (Data x Valor da A√ß√£o) do ticker em quest√£o.\n",
    "        fig.add_trace(go.Scatter(x=x_axis, y=time_serie.values, mode=\"lines\", name=time_serie.name))\n",
    "    \n",
    "    # Adiciona a anota√ß√£o ao gr√°fico\n",
    "    fig.add_annotation(\n",
    "        x=1, y=1, \n",
    "        text=annotation_text, \n",
    "        showarrow=False, \n",
    "        font=dict(size=12, color=\"black\"), \n",
    "        align=\"center\", \n",
    "        xref=\"paper\", yref=\"paper\", \n",
    "        bgcolor=\"white\", opacity=0.7\n",
    "    )\n",
    "    \n",
    "    # Atualiza o layout para permitir destaque ao clicar na legenda.\n",
    "    fig.update_layout(\n",
    "        # Seta um t√≠tulo para o plot.\n",
    "        title=serie_title,\n",
    "        # Seta um t√≠tulo para o eixo x do plot.\n",
    "        xaxis_title=serie_xaxis_title,\n",
    "        # Seta um t√≠tulo para o eixo y do plot.\n",
    "        yaxis_title=serie_yaxis_title  \n",
    "    )\n",
    "\n",
    "    # Exibe o gr√°fico criado.\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a curva de perda do modelo MLP 1 para um objeto Pd.Series e o nomeia como \"MLP 1 Loss Curve\"\n",
    "mlp_1_loss_curve_values = pd.Series(mlp_1.loss_curve_)\n",
    "mlp_1_loss_curve_values.name = \"MLP 1 Loss Curve\"\n",
    "\n",
    "# Converte as pontua√ß√µes de valida√ß√£o do modelo MLP 1 para um objeto Pd.Series e o nomeia como \"MLP 1 Validation Scores\"\n",
    "mlp_1_validation_scores = pd.Series(mlp_1.validation_scores_)\n",
    "mlp_1_validation_scores.name = \"MLP 1 Validation Scores\"\n",
    "\n",
    "# Converte a curva de perda do modelo MLP 2 para um objeto Pd.Series e o nomeia como \"MLP 2 Loss Curve\"\n",
    "mlp_2_loss_curve_values = pd.Series(mlp_2.loss_curve_)\n",
    "mlp_2_loss_curve_values.name = \"MLP 2 Loss Curve\"\n",
    "\n",
    "# Converte as pontua√ß√µes de valida√ß√£o do modelo MLP 2 para um objeto Pd.Series e o nomeia como \"MLP 2 Validation Scores\"\n",
    "mlp_2_validation_scores = pd.Series(mlp_2.validation_scores_)\n",
    "mlp_2_validation_scores.name = \"MLP 2 Validation Scores\"\n",
    "\n",
    "# Converte a curva de perda do melhor modelo MLP encontrado para um objeto Pd.Series e o nomeia como \"Best MLP Loss Curve\"\n",
    "best_mlp_loss_curve_values = pd.Series(best_mlp.loss_curve_)\n",
    "best_mlp_loss_curve_values.name = \"Best MLP Loss Curve\"\n",
    "\n",
    "# Converte as pontua√ß√µes de valida√ß√£o do melhor modelo MLP encontrado para um objeto Pd.Series e o nomeia como \"Best MLP Validation Scores\"\n",
    "best_mlp_validation_scores = pd.Series(best_mlp.validation_scores_)\n",
    "best_mlp_validation_scores.name = \"Best MLP Validation Scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta fun√ß√£o plota duas s√©ries temporais (curva de perda e pontua√ß√£o de valida√ß√£o) para o modelo MLP 1, de modo a podermos visualizar\n",
    "# o desempenho desse modelo ao longo das √©pocas. O eixo X representa as √©pocas e o eixo Y mostra os valores correspondentes de perda e \n",
    "# pontua√ß√£o de valida√ß√£o.\n",
    "plot_multiples_time_series_line_graphs([mlp_1_loss_curve_values, mlp_1_validation_scores], \"Loss Curve vs Validation Scores for the MLP 1\", \"Epoch\", \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*De √≠nicio, observe a sa√≠da da c√©lula abaixo:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula a varia√ß√£o percentual na curva de perda entre a √©poca 5 e a √∫ltima √©poca\n",
    "loss_curve_1_pct_change = ((mlp_1_loss_curve_values[5] - mlp_1_loss_curve_values[len(mlp_1_loss_curve_values) - 1]) / mlp_1_loss_curve_values[5]) * 100\n",
    "\n",
    "# Calcula a varia√ß√£o percentual na pontua√ß√£o de valida√ß√£o (acur√°cia) entre a √©poca 5 e a √∫ltima √©poca\n",
    "validation_scores_1_pct_change = ((mlp_1_validation_scores[5] - mlp_1_validation_scores[len(mlp_1_validation_scores) - 1]) / mlp_1_validation_scores[5]) * 100\n",
    "\n",
    "# Exibe a queda percentual na curva de perda entre a √©poca 5 e a √∫ltima √©poca\n",
    "print(f\"Entre a √©poca 5 e a √©poca {len(mlp_1_loss_curve_values)-1} houve uma queda de {loss_curve_1_pct_change:.2f}% na curva de perda.\\n\")\n",
    "\n",
    "# Exibe o aumento percentual na acur√°cia entre a √©poca 5 e a √∫ltima √©poca (o sinal negativo √© invertido para apresentar um aumento positivo)\n",
    "print(f\"Entre a √©poca 5 e a √©poca {len(mlp_1_validation_scores)-1} houve um aumento de {-validation_scores_1_pct_change:.2f}% na acur√°cia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Com base na sa√≠da da c√©lula acima e no gr√°fico apresentado para esse modelo, podemos concluir que a redu√ß√£o da fun√ß√£o de perda (Loss Curve)n√£o est√° acompanhada por um ganho proporcional na acur√°cia (Validation Scores). Esse desalinhamento sugere que o modelo pode estar subajustado (underfitting), indicando que ele est√° capturando apenas uma parte dos padr√µes presentes nos dados, o que limita sua capacidade de melhorar significativamente a acur√°cia.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta fun√ß√£o plota duas s√©ries temporais (curva de perda e pontua√ß√£o de valida√ß√£o) para o modelo MLP 2, de modo a podermos visualizar\n",
    "# o desempenho desse modelo ao longo das √©pocas. O eixo X representa as √©pocas e o eixo Y mostra os valores correspondentes de perda e \n",
    "# pontua√ß√£o de valida√ß√£o.\n",
    "plot_multiples_time_series_line_graphs([mlp_2_loss_curve_values, mlp_2_validation_scores], \"Loss Curve vs Validation Scores for the MLP 2\", \"Epoch\", \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Com base no gr√°fico apresentado para o Modelo 2, podemos observar que a fun√ß√£o de perda diminui de forma consistente ao longo do treinamento, estabilizando-se em valores baixos, enquanto a acur√°cia aumenta gradualmente (se aproximando cada vez mais de seu valor limite), o que sugere que o modelo est√° generalizando bem para dados n√£o vistos. Al√©m disso, n√£o h√° uma diferen√ßa significativa entre o comportamento das curvas apresentadas. Tais fatores indicam que o modelo n√£o est√° apresentando sinais de overfitting ou underfitting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRlo_Qu6ZQ86"
   },
   "outputs": [],
   "source": [
    "# Esta fun√ß√£o plota duas s√©ries temporais (curva de perda e pontua√ß√£o de valida√ß√£o) para o melhor modelo MLP, de modo a podermos visualizar\n",
    "# o desempenho desse modelo ao longo das √©pocas. O eixo X representa as √©pocas e o eixo Y mostra os valores correspondentes de perda e \n",
    "# pontua√ß√£o de valida√ß√£o.\n",
    "plot_multiples_time_series_line_graphs([best_mlp_loss_curve_values, best_mlp_validation_scores], \"Loss Curve vs Validation Scores for the Best MLP\", \"Epoch\", \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*O gr√°fico acima √© bastante semelhante ao apresentado para o Modelo 2, pois as duas redes possuem configura√ß√µes id√™nticas, com a √∫nica diferen√ßa sendo o n√∫mero de √©pocas, o que faz o Modelo 3 apresentar um desempenho ligeiramente superior em termos de acur√°cia. De forma mais espec√≠fica, podemos observar que o pequeno aumento na acur√°cia do terceiro modelo, em compara√ß√£o ao segundo, √© acompanhado por uma redu√ß√£o na fun√ß√£o de perda. Al√©m disso, assim como no Modelo 2, n√£o h√° diferen√ßa significativa no comportamento das duas curvas apresentadas. Tais fatores indicam que o Modelo 3 tamb√©m n√£o apresenta sinais de overfitting ou underfitting, tal como o modelo 2.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhJSZM41ZNw4"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3twj4RlHQok"
   },
   "source": [
    "# 4Ô∏è‚É£ Tarefa 04: Resultados e Visualiza√ß√µes ü§ûüèª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOOBIO28ZK1m"
   },
   "source": [
    "## üê≥ Item a)\n",
    "\n",
    "Gere e apresente uma matriz de confus√£o que mostre a distribui√ß√£o das previs√µes do melhor modelo. Quais as m√©tricas de Acur√°cia, Precis√£o, Recall e F1-Score para esse modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N4EmJVEZRzP"
   },
   "outputs": [],
   "source": [
    "# Gera a matriz de confus√£o comparando os r√≥tulos verdadeiros (y_test) com as previs√µes do modelo (best_y_pred).\n",
    "conf_matrix = confusion_matrix(y_test, best_y_pred)\n",
    "\n",
    "# Exibe a matriz de confus√£o gerada acima.\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ser√° criado um mapa de calor junto da matriz de confus√£o para melhorar a visualiza√ß√£o da matriz de confus√£o.\n",
    "\n",
    "# Cria uma nova Figure.\n",
    "fig = go.Figure(\n",
    "    # Adiciona √† Figure criada um heatmap.\n",
    "    data=go.Heatmap(\n",
    "        z=conf_matrix,  # Seta os valores da matriz de confus√£o como o \"eixo z\" do heatmap.\n",
    "        x=[\"Classe 0\", \"Classe 1\", \"Classe 2\", \"Classe 3\", \"Classe 4\",\n",
    "           \"Classe 5\", \"Classe 6\", \"Classe 7\", \"Classe 8\", \"Classe 9\"],  # R√≥tulos do eixo X (classes previstas).\n",
    "        y=[\"Classe 0\", \"Classe 1\", \"Classe 2\", \"Classe 3\", \"Classe 4\",\n",
    "           \"Classe 5\", \"Classe 6\", \"Classe 7\", \"Classe 8\", \"Classe 9\"],  # R√≥tulos do eixo Y (classes reais).\n",
    "        colorscale=\"Blues\",  # Escala de cores do mapa de calor.\n",
    "        text=conf_matrix,  # Adiciona os valores da matriz como texto no gr√°fico.\n",
    "        texttemplate=\"%{text}\"  # Define o formato do texto exibido no gr√°fico.\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ajusta o layout do heatmap da matriz de confus√£o.\n",
    "fig.update_layout(\n",
    "    title=\"Mapa de calor da Matriz de Confus√£o\",           # Seta o t√≠tulo do plot.\n",
    "    xaxis=dict(title=\"Classe Predita\"),                    # Seta o t√≠tulo do eixo X.\n",
    "    yaxis=dict(title=\"Classe Real\", autorange=\"reversed\"), # Seta o t√≠tulo do eixo Y.\n",
    ")\n",
    "\n",
    "# Exibe o plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afZy1_QnZR1H"
   },
   "outputs": [],
   "source": [
    "# Printa um relat√≥rio detalhado dos resultados da classifica√ß√£o (Incluindo Acur√°cia, Precis√£o, Recall e f1-score).\n",
    "print(classification_report(y_test, best_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ1EnPzLZJv1"
   },
   "source": [
    "## üê∏ Item b)\n",
    "\n",
    "Exiba gr√°ficos que mostram a evolu√ß√£o da acur√°cia e da perda (`Loss`) durante o treinamento do melhor modelo encontrado no item 3c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drg2DaDCZSP7"
   },
   "outputs": [],
   "source": [
    "# Define os nomes das s√©ries para identificar a evolu√ß√£o da acur√°cia e da fun√ß√£o de perda no gr√°fico que ser√° plotado.\n",
    "best_mlp_loss_curve_values.name = \"Evolu√ß√£o da Acur√°cia\"\n",
    "best_mlp_validation_scores.name = \"Evolu√ß√£o da Fun√ß√£o de Perda\"\n",
    "\n",
    "# Esta fun√ß√£o plota duas s√©ries temporais (curva de perda e pontua√ß√£o de valida√ß√£o) para o melhor modelo MLP, de modo a podermos visualizar\n",
    "# o desempenho desse modelo ao longo das √©pocas. O eixo X representa as √©pocas e o eixo Y mostra os valores correspondentes de perda e \n",
    "# pontua√ß√£o de valida√ß√£o.\n",
    "plot_multiples_time_series_line_graphs([best_mlp_loss_curve_values, best_mlp_validation_scores], \"Loss Curve vs Validation Scores for the Best MLP\", \"Epoch\", \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvHuhj41ZIem"
   },
   "source": [
    "## ü¶ñ Item c)\n",
    "\n",
    "Escolha algumas imagens do conjunto de teste e mostre previs√µes do seu modelo, com acertos e erros. Discuta quais fatores podem ter contribu√≠do para essas previs√µes corretas e incorretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTDoZCiBZSvI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTW6Y5cuZSxj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7115SaQnZS0J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFtgYlQfZLp6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndh6bvtSHipL"
   },
   "source": [
    "# 5Ô∏è‚É£ Tarefa 05: Lembrete *Kaggle* e Documenta√ß√£o üóÉÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FiWgUycHnuC"
   },
   "source": [
    "## üòÆ‚Äçüí® Item a)\n",
    "\n",
    "# Lembre-se de publicar no *Kaggle* com o t√≠tulo correto e padronizado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HCM3vhMIc-E"
   },
   "source": [
    "## üôèüèª Item b)\n",
    "\n",
    "# Lembre-se de documentar adequadamente seu c√≥digo e conclus√µes!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
